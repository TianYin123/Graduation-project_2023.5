{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4964,"status":"ok","timestamp":1683368100280,"user":{"displayName":"bbg Edison","userId":"10479035721633275312"},"user_tz":-480},"id":"LM8dBUROIKCQ"},"outputs":[],"source":["import numpy as np\n","import torch\n","import os\n","import random\n","from torch.utils.data import Dataset\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import nibabel as nib\n","\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from torch.utils.data import ConcatDataset\n","import torchvision.models as models\n","import copy"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683368100281,"user":{"displayName":"bbg Edison","userId":"10479035721633275312"},"user_tz":-480},"id":"p3ooqatWIKCS"},"outputs":[],"source":["random.seed(3407)\n","rmb_label = {\"ASD\": 0, \"TD\": 1}      # 设置标签\n","\n","class MultiModalDataset(Dataset):\n","    def __init__(self, data_dirho, data_diraal,data_direz , data_dircsv, transform=None):\n","        \"\"\" \n","        ABIDE_db的Dataset\n","        :param data_dir: str, 数据集所在路径\n","        :param transform: torch.transform，数据预处理\n","        \"\"\"\n","        self.label_name = {\"ASD\": 0, \"TD\": 1}\n","        self.data_infocsv = self.get_csv_info(data_dircsv)  # data_info存储所有txt路径和标签，在DataLoader中通过index读取样本\n","        self.data_infoez = self.get_1D_info(data_direz)  # data_info存储所有txt路径和标签，在DataLoader中通过index读取样本\n","        self.data_infoho = self.get_1D_info(data_dirho)\n","        self.data_infoaal = self.get_1D_info(data_diraal)\n","\n","        self.transform = transform\n","        \n","\n","        \n","    def __getitem__(self, index):\n","        path_csv, label_csv = self.data_infocsv[index]\n","        txt_data = np.loadtxt(path_csv, delimiter=',')\n","        label = label_csv\n","        csv = torch.from_numpy(txt_data).float().unsqueeze(0)\n","        ez = self.process_data(method='ez',index=index,labels=label_csv)\n","        ho = self.process_data(method='ho',index=index,labels=label_csv)\n","        aal = self.process_data(method='aal',index=index,labels=label_csv)\n","\n","        if self.transform is not None:\n","            txt = 1   # 在这里做transform，转为tensor等等\n","\n","        return ho,aal,ez,csv,label\n","\n","    def __len__(self):\n","        return len(self.data_infocsv)\n","\n","    @staticmethod\n","    def get_csv_info(data_dir):\n","        data_infocsv = list()\n","        for root, dirs, _ in os.walk(data_dir):\n","            # 遍历类别\n","            for sub_dir in dirs:\n","                txt_names = os.listdir(os.path.join(root, sub_dir))\n","                txt_names = list(filter(lambda x: x.endswith('.csv'), txt_names))\n","\n","                # 遍历txt\n","                for i in range(len(txt_names)):\n","                    txt_name = txt_names[i]\n","                    path_txt = os.path.join(root, sub_dir, txt_name)\n","                    label = rmb_label[sub_dir]\n","                    data_infocsv.append((path_txt, int(label)))\n","                    data_infocsv = sorted(data_infocsv)\n","\n","        return data_infocsv\n","    \n","    def get_1D_info(self,data_dir):\n","        data_infonii = list()\n","        for root, dirs, _ in os.walk(data_dir):\n","            # 遍历类别\n","            for sub_dir in dirs:\n","                txt_names = os.listdir(os.path.join(root, sub_dir))\n","                txt_names = list(filter(lambda x: x.endswith('.1D'), txt_names))\n","\n","                # 遍历txt\n","                for i in range(len(txt_names)):\n","                    txt_name = txt_names[i]\n","                    path_txt = os.path.join(root, sub_dir, txt_name)\n","                    label = rmb_label[sub_dir]\n","                    data_infonii.append((path_txt, int(label)))\n","                    data_infonii = sorted(data_infonii)\n","        return data_infonii\n","    \n","    def process_data(self,method,index,labels):\n","        if method == 'ez':\n","            path, label = self.data_infoez[index]\n","            txt_data = np.loadtxt(path)\n","            cor = np.corrcoef(txt_data.T)\n","            cor = torch.from_numpy(cor).float().unsqueeze(0)\n","        if method == 'ho':\n","            path, label = self.data_infoho[index]\n","            txt_data = np.loadtxt(path)\n","            cor = np.corrcoef(txt_data.T)\n","            file1 = np.pad(cor, ((0, 5), (0, 5)), mode='constant')\n","            cor = torch.from_numpy(file1).float().unsqueeze(0)\n","        if method == 'aal':\n","            path, label = self.data_infoaal[index]\n","            txt_data = np.loadtxt(path)\n","            cor = np.corrcoef(txt_data.T)\n","            cor = torch.from_numpy(cor).float().unsqueeze(0)\n","        if labels != label:\n","            print('Error: label not match!')\n","            print('the error 1D:{}',path)\n","        \n","        \n","        return cor"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683368100282,"user":{"displayName":"bbg Edison","userId":"10479035721633275312"},"user_tz":-480},"id":"ri_trnWjIKCU"},"outputs":[],"source":["class ChannelAttention(nn.Module):\n","    def __init__(self, in_planes, ratio=16):\n","        super(ChannelAttention, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.max_pool = nn.AdaptiveMaxPool2d(1)\n"," \n","        self.fc1   = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)\n","        self.relu1 = nn.ReLU()\n","        self.fc2   = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\n"," \n","        self.sigmoid = nn.Sigmoid()\n"," \n","    def forward(self, x): \n","        # the shape of x is (b c h w)\n","        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n","        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n","        out = avg_out + max_out\n","        attn = self.sigmoid(out) # (b c)\n","        attn = torch.squeeze(attn, dim=3)\n","        attn = torch.squeeze(attn, dim=2)\n","        x = x * attn[:, :, None, None]\n","        return x\n","    \n","class SpatialAttention(nn.Module):\n","    def __init__(self, kernel_size=7):\n","        super(SpatialAttention, self).__init__()\n"," \n","        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n","        padding = 3 if kernel_size == 7 else 1\n"," \n","        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n","        self.sigmoid = nn.Sigmoid()\n"," \n","    def forward(self, x): \n","        # the shape of x is (b c h w)\n","        avg_out = torch.mean(x, dim=1, keepdim=True)\n","        max_out, _ = torch.max(x, dim=1, keepdim=True)\n","        attn = torch.cat([avg_out, max_out], dim=1)\n","        attn = self.conv1(attn) # b 1 h w\n","        attn = self.sigmoid(attn)\n","        attn = torch.squeeze(attn, dim=1) # b h w\n","        x = attn[:, None, :, :] * x\n","        return x"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683368100283,"user":{"displayName":"bbg Edison","userId":"10479035721633275312"},"user_tz":-480},"id":"JfW50KhdIKCU"},"outputs":[],"source":["class FeatureExtractorCNN(nn.Module):\n","    def __init__(self):\n","        super(FeatureExtractorCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        self.fc1 = nn.Linear(32 * 29 * 29, 128)\n","\n","        # Add attention modules\n","        self.channel_attention2 = ChannelAttention(32)\n","        self.spatial_attention2 = SpatialAttention()\n","\n","        # Add outputs lists for each layer\n","        self.outputs_conv1 = []\n","        self.outputs_pool1 = []\n","        self.outputs_conv2 = []\n","        self.outputs_channel_attention2 = []\n","        self.outputs_spatial_attention2 = []\n","        self.outputs_pool2 = []\n","        self.outputs_fc1 = []\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        self.outputs_conv1.append(x.detach())\n","        \n","        x = self.pool(x)\n","        self.outputs_pool1.append(x.detach())\n","        \n","        x = F.relu(self.conv2(x))\n","        self.outputs_conv2.append(x.detach())\n","        \n","        # Apply channel attention and spatial attention after conv2\n","        x = self.channel_attention2(x)\n","        self.outputs_channel_attention2.append(x.detach())\n","        \n","        x = self.spatial_attention2(x)\n","        self.outputs_spatial_attention2.append(x.detach())\n","\n","        x = self.pool(x)\n","        self.outputs_pool2.append(x.detach())\n","        \n","        x = x.view(-1, 32 * 29 * 29)\n","        x = F.relu(self.fc1(x))\n","        self.outputs_fc1.append(x.detach())\n","\n","        return x\n","\n","    # Add methods to get the outputs of each layer\n","    def get_outputs_conv1(self):\n","        return self.outputs_conv1\n","    \n","    def get_outputs_pool1(self):\n","        return self.outputs_pool1\n","    \n","    def get_outputs_conv2(self):\n","        return self.outputs_conv2\n","    \n","    def get_outputs_channel_attention2(self):\n","        return self.outputs_channel_attention2\n","    \n","    def get_outputs_spatial_attention2(self):\n","        return self.outputs_spatial_attention2\n","\n","    def get_outputs_pool2(self):\n","        return self.outputs_pool2\n","\n","    def get_outputs_fc1(self):\n","        return self.outputs_fc1\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683368100283,"user":{"displayName":"bbg Edison","userId":"10479035721633275312"},"user_tz":-480},"id":"tJQEeXIhIKCV"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class SelfAttention(nn.Module):\n","    def __init__(self, dim0=128): # dim0 should be the channel number of each input, i.e., x1, x2, x3,...\n","        super().__init__()\n","        self.attend = nn.Softmax(dim=-1)\n","        self.scale = dim0 ** -0.5\n","\n","    def forward(self, x1, x2, x3, x4):\n","        # the shape of x1, x2, x3,... is (b 1 d)\n","        x = torch.cat((x1, x2, x3, x4), 1) # the shape of x is (b 4 d)\n","        dots = torch.matmul(x, x.transpose(-1, -2)) * self.scale\n","        attn = self.attend(dots) # the shape of x is (b, 4, 4)\n","        importance = torch.sum(attn, dim=1) # the shape of importance is (b, 4)\n","        importance = self.attend(importance)\n","        x = x * importance[:, :, None]\n","        x = x.view(x.shape[0], -1) # this can be sended into your classifer\n","        return x"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":338,"status":"ok","timestamp":1683368103011,"user":{"displayName":"bbg Edison","userId":"10479035721633275312"},"user_tz":-480},"id":"9HVF2cenIKCV"},"outputs":[],"source":["class MultiModalClassifier(nn.Module):\n","    def __init__(self, num_classes=2):\n","        super(MultiModalClassifier, self).__init__()\n","        self.feature_extractor_ho = FeatureExtractorCNN()\n","        self.feature_extractor_aal = FeatureExtractorCNN()\n","        self.feature_extractor_ez = FeatureExtractorCNN()\n","        self.feature_extractor_csv = FeatureExtractorCNN()\n","\n","        # Add the self attention layer\n","        self.self_attention = SelfAttention()\n","\n","        # Fully connected layer to combine the features from both extractors and perform classification\n","        self.classifier = nn.Sequential(\n","            nn.Linear(128*4, 256),  # Adjust the input size to match the output of the self attention layer\n","            nn.ReLU(inplace=True),\n","            nn.Linear(256, num_classes)\n","        )\n","\n","    def forward(self,x_csv,x_ho,x_ez,x_aal):\n","        features_csv = self.feature_extractor_csv(x_csv)\n","        features_ho = self.feature_extractor_ho(x_ho)\n","        features_ez = self.feature_extractor_ez(x_ez)\n","        features_aal = self.feature_extractor_aal(x_aal)\n","\n","        # Apply self attention on the features\n","        combined_features = torch.cat((features_ho, features_ez,features_aal,features_csv), dim=1)\n","\n","        # Pass the combined features through the classifier\n","        output = self.classifier(combined_features)\n","        return output\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":437,"status":"ok","timestamp":1683368171335,"user":{"displayName":"bbg Edison","userId":"10479035721633275312"},"user_tz":-480},"id":"H1IhipQFIKCV"},"outputs":[],"source":["csv_split_dir = os.path.join('/Users/yangzongxian/Study_profiles/ABIDE_Data/easy/not modify/csv_split')  \n","csv_train_dir = os.path.join(csv_split_dir, \"train\")\n","csv_valid_dir = os.path.join(csv_split_dir, \"valid\")\n","csv_test_dir  = os.path.join(csv_split_dir, \"test\") \n","aal_split_dir = os.path.join('/Users/yangzongxian/Study_profiles/ABIDE_Data/easy/not modify/aal_split')  \n","aal_train_dir = os.path.join(aal_split_dir, \"train\")\n","aal_valid_dir = os.path.join(aal_split_dir, \"valid\")\n","aal_test_dir  = os.path.join(aal_split_dir, \"test\") \n","ho_split_dir = os.path.join('/Users/yangzongxian/Study_profiles/ABIDE_Data/easy/not modify/rho_split')  \n","ho_train_dir = os.path.join(ho_split_dir, \"train\")\n","ho_valid_dir = os.path.join(ho_split_dir, \"valid\")\n","ho_test_dir  = os.path.join(ho_split_dir, \"test\") \n","ez_split_dir = os.path.join('/Users/yangzongxian/Study_profiles/ABIDE_Data/easy/not modify/ez_split')  \n","ez_train_dir = os.path.join(ez_split_dir, \"train\")\n","ez_valid_dir = os.path.join(ez_split_dir, \"valid\")\n","ez_test_dir  = os.path.join(ez_split_dir, \"test\") "]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2201635,"status":"error","timestamp":1683370648756,"user":{"displayName":"bbg Edison","userId":"10479035721633275312"},"user_tz":-480},"id":"XS6vq1PYIKCV","outputId":"0921a8fb-a8f7-4b26-eb0d-306dff96954d"},"outputs":[{"name":"stdout","output_type":"stream","text":["训练\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Users/yangzongxian/opt/anaconda3/envs/pytorch/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Users/yangzongxian/opt/anaconda3/envs/pytorch/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","AttributeError: Can't get attribute 'MultiModalDataset' on <module '__main__' (built-in)>\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     50\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 51\u001b[0m \u001b[39mfor\u001b[39;00m i, (ho,aal,ez,csv,label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(train_loader):\n\u001b[1;32m     52\u001b[0m     ho, aal, ez, csv, labels \u001b[39m=\u001b[39m ho\u001b[39m.\u001b[39mto(device), aal\u001b[39m.\u001b[39mto(device), ez\u001b[39m.\u001b[39mto(device),csv\u001b[39m.\u001b[39mto(device),label\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     53\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n","File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n","File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n","File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n","File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n","File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n","File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n","File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n","File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[39m.\u001b[39;49mwrite(fp\u001b[39m.\u001b[39;49mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# 定义超参数\n","input_size = [116,116]\n","batch_size = 128\n","learning_rate = 0.001\n","num_epochs = 100\n","num_classes = 2\n","log_interval = 8\n","val_interval = 8\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MultiModalClassifier()\n","model = model.to(device)\n","# print(model)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)     # 设置学习率下降策略\n","\n","# 实例化数据集和数据加载器\n","\n","train_dataset = MultiModalDataset(ho_train_dir,aal_train_dir,ez_train_dir,csv_train_dir, transform=None)\n","valid_dataset = MultiModalDataset(ho_valid_dir,aal_valid_dir,ez_valid_dir,csv_valid_dir, transform=None)\n","test_dataset = MultiModalDataset(ho_test_dir,aal_test_dir,ez_test_dir,csv_test_dir, transform=None)\n","#CNN 图像模型dataloader\n","# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn = collate_fn,num_workers = num_workers)\n","# valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False,collate_fn = collate_fn,num_workers = num_workers)\n","#非CNN \n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers = 8)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False,num_workers =2)\n","\n","print('训练')\n","train_losses = []\n","train_accs = []\n","valid_losses = []\n","valid_accs = []\n","best_val_loss = float('inf')\n","best_val_acc = 0.0\n","loss_patience = 10\n","acc_patience = 10\n","loss_count = 0\n","acc_count = 0\n","model_bestloss = None\n","model_bestacc = None\n","# ============================ step 5/5 训练 ============================\n","# 训练和验证\n","for epoch in range(num_epochs):\n","    # 训练阶段\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    for i, (ho,aal,ez,csv,label) in enumerate(train_loader):\n","        ho, aal, ez, csv, labels = ho.to(device), aal.to(device), ez.to(device),csv.to(device),label.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(ho, aal, ez, csv)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * csv.size(0)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += label.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    train_loss = running_loss / len(train_dataset)\n","    train_acc = correct / total\n","    train_losses.append(train_loss)\n","    train_accs.append(train_acc)\n","\n","    # 验证阶段\n","    model.eval()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        total = 0\n","        correct = 0\n","        for ho,aal,ez,csv,label in valid_loader:\n","            ho, aal, ez, csv, labels = ho.to(device), aal.to(device), ez.to(device),csv.to(device),label.to(device)\n","            outputs = model(ho, aal, ez, csv)\n","            loss = criterion(outputs, labels)\n","            \n","            running_loss += loss.item() * csv.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += label.size(0)\n","            correct += (predicted == labels).sum().item()\n","            # pred = outputs.argmax(dim=1)\n","            # print(f\"Sample: predicted={pred.item()}, target={label.item()},matched?={label.item() == pred.item()}\")\n","\n","    valid_loss = running_loss / len(valid_dataset)\n","    valid_acc = correct / total\n","    valid_losses.append(valid_loss)\n","    valid_accs.append(valid_acc)\n","\n","    # 打印训练过程中的指标\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.4f}\")\n","    # 保存模型\n","    if epoch > 40 :\n","      if valid_loss < best_val_loss:\n","          best_val_loss = valid_loss\n","          model_bestloss = copy.deepcopy(model)\n","          loss_count = 0\n","      else:\n","          loss_count += 1\n","\n","      if valid_acc > best_val_acc:\n","          best_val_acc = valid_acc\n","          model_bestacc = copy.deepcopy(model)\n","          acc_count = 0\n","      else:\n","          acc_count += 1\n","\n","      # 如果损失连续增加，且准确率不再增加，则停止训练\n","      if loss_count >= loss_patience and acc_count >= acc_patience:\n","          print(\"Early stopping triggered.\")\n","          break\n","\n","# 保存最佳模型\n","torch.save(model_bestacc.state_dict(), 'accmodel_2attention.pth')\n","torch.save(model_bestloss.state_dict(), 'lossmodel_2attention.pth')\n","\n","\n","# 绘制训练和验证指标的图表\n","fig, axs = plt.subplots(2, 1, figsize=(10, 12))\n","axs[0].plot(train_accs, label='Train Accuracy')\n","axs[0].plot(valid_accs, label='Validation Accuracy')\n","axs[0].legend()\n","axs[0].set_xlabel('Epoch')\n","axs[0].set_ylabel('Value')\n","axs[0].set_title('Training and Validation Metrics')\n","\n","axs[1].plot(train_losses, label='Train Loss')\n","axs[1].plot(valid_losses, label='Validation Loss')\n","axs[1].legend()\n","axs[1].set_xlabel('Epoch')\n","axs[1].set_ylabel('Value')\n","axs[1].set_title('Training and Validation Metrics')\n","\n","plt.show()\n","\n","# 在测试阶段，我们需要跟踪的指标\n","TP = 0\n","TN = 0\n","FP = 0\n","FN = 0\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","# 开始测试\n","print('Bestloss')\n","model_bestloss.eval()\n","with torch.no_grad():\n","    for ho, aal, ez, csv, label in test_loader:\n","        ho, aal, ez, csv, labels = ho.to(device), aal.to(device), ez.to(device), csv.to(device), label.to(device)\n","        outputs = model(aal)\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        for i in range(len(labels)):\n","            true_label = labels[i]\n","            pred_label = predicted[i]\n","            if true_label == 1 and pred_label == 1:\n","                TP += 1\n","            elif true_label == 0 and pred_label == 0:\n","                TN += 1\n","            elif true_label == 0 and pred_label == 1:\n","                FP += 1\n","            elif true_label == 1 and pred_label == 0:\n","                FN += 1\n","\n","# 计算各项指标\n","accuracy = (TP + TN) / (TP + TN + FP + FN)\n","sensitivity = TP / (TP + FN)\n","specificity = TN / (TN + FP)\n","ppv = TP / (TP + FP)\n","npv = TN / (TN + FN)\n","\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Sensitivity: {sensitivity:.4f}\")\n","print(f\"Specificity: {specificity:.4f}\")\n","print(f\"Positive Predictive Value: {ppv:.4f}\")\n","print(f\"Negative Predictive Value: {npv:.4f}\")\n","\n","print('\\nBestacc')\n","TP = 0\n","TN = 0\n","FP = 0\n","FN = 0\n","model_bestacc.eval()\n","with torch.no_grad():\n","    for ho, aal, ez, csv, label in test_loader:\n","        ho, aal, ez, csv, labels = ho.to(device), aal.to(device), ez.to(device), csv.to(device), label.to(device)\n","        outputs = model(aal)\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        for i in range(len(labels)):\n","            true_label = labels[i]\n","            pred_label = predicted[i]\n","            if true_label == 1 and pred_label == 1:\n","                TP += 1\n","            elif true_label == 0 and pred_label == 0:\n","                TN += 1\n","            elif true_label == 0 and pred_label == 1:\n","                FP += 1\n","            elif true_label == 1 and pred_label == 0:\n","                FN += 1\n","\n","# 计算各项指标\n","accuracy = (TP + TN) / (TP + TN + FP + FN)\n","sensitivity = TP / (TP + FN)\n","specificity = TN / (TN + FP)\n","ppv = TP / (TP + FP)\n","npv = TN / (TN + FN)\n","\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Sensitivity: {sensitivity:.4f}\")\n","print(f\"Specificity: {specificity:.4f}\")\n","print(f\"Positive Predictive Value: {ppv:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8563,"status":"ok","timestamp":1683370763884,"user":{"displayName":"bbg Edison","userId":"10479035721633275312"},"user_tz":-480},"id":"xwNXkaZatp2x","outputId":"c0a601c8-44cb-4ca1-9eff-15f3b356b29b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Bestloss\n","Accuracy: 0.7093\n","Sensitivity: 0.6522\n","Specificity: 0.7750\n","Positive Predictive Value: 0.7692\n","Negative Predictive Value: 0.6596\n","\n","Bestacc\n","Accuracy: 0.7093\n","Sensitivity: 0.6522\n","Specificity: 0.7750\n","Positive Predictive Value: 0.7692\n"]}],"source":["\n","# 在测试阶段，我们需要跟踪的指标\n","TP = 0\n","TN = 0\n","FP = 0\n","FN = 0\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","# 开始测试\n","print('Bestloss')\n","model_bestloss.eval()\n","with torch.no_grad():\n","    for ho, aal, ez, csv, label in test_loader:\n","        ho, aal, ez, csv, labels = ho.to(device), aal.to(device), ez.to(device), csv.to(device), label.to(device)\n","        outputs = model(ho, aal, ez, csv)\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        for i in range(len(labels)):\n","            true_label = labels[i]\n","            pred_label = predicted[i]\n","            if true_label == 1 and pred_label == 1:\n","                TP += 1\n","            elif true_label == 0 and pred_label == 0:\n","                TN += 1\n","            elif true_label == 0 and pred_label == 1:\n","                FP += 1\n","            elif true_label == 1 and pred_label == 0:\n","                FN += 1\n","\n","# 计算各项指标\n","accuracy = (TP + TN) / (TP + TN + FP + FN)\n","sensitivity = TP / (TP + FN)\n","specificity = TN / (TN + FP)\n","ppv = TP / (TP + FP)\n","npv = TN / (TN + FN)\n","\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Sensitivity: {sensitivity:.4f}\")\n","print(f\"Specificity: {specificity:.4f}\")\n","print(f\"Positive Predictive Value: {ppv:.4f}\")\n","print(f\"Negative Predictive Value: {npv:.4f}\")\n","\n","print('\\nBestacc')\n","TP = 0\n","TN = 0\n","FP = 0\n","FN = 0\n","model_bestacc.eval()\n","with torch.no_grad():\n","    for ho, aal, ez, csv, label in test_loader:\n","        ho, aal, ez, csv, labels = ho.to(device), aal.to(device), ez.to(device), csv.to(device), label.to(device)\n","        outputs = model(ho, aal, ez, csv)\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        for i in range(len(labels)):\n","            true_label = labels[i]\n","            pred_label = predicted[i]\n","            if true_label == 1 and pred_label == 1:\n","                TP += 1\n","            elif true_label == 0 and pred_label == 0:\n","                TN += 1\n","            elif true_label == 0 and pred_label == 1:\n","                FP += 1\n","            elif true_label == 1 and pred_label == 0:\n","                FN += 1\n","\n","# 计算各项指标\n","accuracy = (TP + TN) / (TP + TN + FP + FN)\n","sensitivity = TP / (TP + FN)\n","specificity = TN / (TN + FP)\n","ppv = TP / (TP + FP)\n","npv = TN / (TN + FN)\n","\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Sensitivity: {sensitivity:.4f}\")\n","print(f\"Specificity: {specificity:.4f}\")\n","print(f\"Positive Predictive Value: {ppv:.4f}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
