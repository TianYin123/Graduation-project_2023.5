{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "random.seed(1)\n",
    "rmb_label = {\"ASD\": 0, \"TD\": 1}      # 设置标签\n",
    "\n",
    "class ABIDEtxtDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        \"\"\"\n",
    "        ABIDE_db的Dataset\n",
    "        :param data_dir: str, 数据集所在路径\n",
    "        :param transform: torch.transform，数据预处理\n",
    "        \"\"\"\n",
    "        self.label_name = {\"ASD\": 0, \"TD\": 1}\n",
    "        self.data_info = self.get_txt_info(data_dir)  # data_info存储所有txt路径和标签，在DataLoader中通过index读取样本\n",
    "        self.transform = transform\n",
    "        print('Number of samples:', len(self.data_info))\n",
    "        print('Sample info:', self.data_info[0])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        path_txt, label = self.data_info[index]\n",
    "        print(path_txt)\n",
    "        txt_data = np.loadtxt(path_txt)\n",
    "        txt_data_tensor = torch.from_numpy(txt_data)\n",
    "        print(txt_data_tensor.shape)\n",
    "        cor = np.corrcoef(txt_data.T)\n",
    "        # 将对称矩阵转换成上三角矩阵\n",
    "        tri_matrix = np.triu(cor)\n",
    "        # 转换为上三角矩阵\n",
    "        upper_triangular = np.triu(tri_matrix,1)\n",
    "        idx = np.nonzero(upper_triangular)\n",
    "        # 将非零数据保存在1维张量中\n",
    "        non_zero_values = upper_triangular[idx]\n",
    "        # 将cor转换为Tensor\n",
    "        cor = torch.from_numpy(non_zero_values).float()\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            txt = self.transform(txt)   # 在这里做transform，转为tensor等等\n",
    "\n",
    "        return cor, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_txt_info(data_dir):\n",
    "        data_info = list()\n",
    "        for root, dirs, _ in os.walk(data_dir):\n",
    "            # 遍历类别\n",
    "            for sub_dir in dirs:\n",
    "                txt_names = os.listdir(os.path.join(root, sub_dir))\n",
    "                txt_names = list(filter(lambda x: x.endswith('.1D'), txt_names))\n",
    "\n",
    "                # 遍历txt\n",
    "                for i in range(len(txt_names)):\n",
    "                    txt_name = txt_names[i]\n",
    "                    path_txt = os.path.join(root, sub_dir, txt_name)\n",
    "                    label = rmb_label[sub_dir]\n",
    "                    data_info.append((path_txt, int(label)))\n",
    "\n",
    "        return data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSelfAttention\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, input_channels):\n\u001b[1;32m      3\u001b[0m         \u001b[39msuper\u001b[39m(SelfAttention, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Conv2d(input_channels, input_channels, kernel_size=1)\n",
    "        self.key = nn.Conv2d(input_channels, input_channels, kernel_size=1)\n",
    "        self.value = nn.Conv2d(input_channels, input_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        b, c, h, w = q.size()\n",
    "        q = q.view(b, c, -1)\n",
    "        k = k.view(b, c, -1)\n",
    "        v = v.view(b, c, -1)\n",
    "\n",
    "        attention_weights = F.softmax(torch.bmm(q.permute(0, 2, 1), k), dim=-1)\n",
    "        out = torch.bmm(v, attention_weights.permute(0, 2, 1))\n",
    "        out = out.view(b, c, h, w)\n",
    "        \n",
    "        return out\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.attention = SelfAttention(64)  # Add the attention layer\n",
    "        self.fc1 = nn.Linear(64 * 116 * 116, 512)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.attention(x)  # Apply the attention layer\n",
    "        x = x.view(-1, 64 * 116 * 116)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, dropout=0.5)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始化隐藏层状态\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # 前向传播 RNN\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.dropout(out)\n",
    "        # 将输出结果展平\n",
    "        out = out[:, -1, :]\n",
    "        # 全连接层\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes):\n",
    "        super(SAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_sizes[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_sizes[2], hidden_sizes[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_sizes[3], hidden_sizes[4])\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_sizes[4], hidden_sizes[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_sizes[3], hidden_sizes[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_sizes[2], hidden_sizes[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_sizes[1], hidden_sizes[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_sizes[0], input_size)\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_sizes[4], 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        encoded = x\n",
    "        x = self.decoder(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 705\n",
      "Sample info: ('/Users/yangzongxian/Study_profiles/ABIDE_Data/ABIDE_roiaal/aal_split/train/ASD/USM_0050497_rois_aal.1D', 0)\n",
      "Number of samples: 89\n",
      "Sample info: ('/Users/yangzongxian/Study_profiles/ABIDE_Data/ABIDE_roiaal/aal_split/valid/ASD/UM_1_0050277_rois_aal.1D', 0)\n",
      "训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangzongxian/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/yangzongxian/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x6670 and 116x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m data, label \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), label\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     76\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 77\u001b[0m outputs \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     78\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, label)\n\u001b[1;32m     79\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m, in \u001b[0;36mSAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 30\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[1;32m     31\u001b[0m     encoded \u001b[39m=\u001b[39m x\n\u001b[1;32m     32\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(x)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x6670 and 116x512)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "valid_losses = []\n",
    "valid_accs = []\n",
    "split_dir = os.path.join(\"/Users/yangzongxian/Study_profiles/ABIDE_Data/ABIDE_roiaal/aal_split\")  \n",
    "train_dir = os.path.join(split_dir, \"train\")\n",
    "valid_dir = os.path.join(split_dir, \"valid\")\n",
    "test_dir  = os.path.join(split_dir, \"test\") \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 定义超参数\n",
    "input_size = 116\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "hidden_size = [512, 256, 128, 64, 32]\n",
    "num_layers = 8\n",
    "num_classes = 2\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data = [d[0] for d in batch]\n",
    "    label = [d[1] for d in batch]\n",
    "    # 为数据添加一个额外的维度，以便将其转换为形状为 [batch_size, 1, height, width] 的张量\n",
    "    data = [d.unsqueeze(0) for d in data]\n",
    "    # 将多个数据合并为一个batch\n",
    "    data = torch.stack(data, dim=0)\n",
    "    label = torch.tensor(label)\n",
    "    return data, label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 实例化数据集和数据加载器\n",
    "train_dataset = ABIDEtxtDataset(train_dir, transform=None)\n",
    "valid_dataset = ABIDEtxtDataset(valid_dir, transform=None)\n",
    "#CNN 图像模型dataloader\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn = collate_fn)\n",
    "# valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False,collate_fn = collate_fn)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 实例化模型、损失函数和优化器\n",
    "# model = SqueezeNet2D(2)\n",
    "# model = MyCNN()\n",
    "# model = RNNModel(input_size,hidden_size,num_layers,num_classes)\n",
    "model = SAE(input_size,hidden_size)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print('训练')\n",
    "# 训练和验证\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (data, label) in enumerate(train_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for data, label in valid_loader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, label)\n",
    "            running_loss += loss.item() * data.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "\n",
    "    valid_loss = running_loss / len(valid_dataset)\n",
    "    valid_acc = correct / total\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accs.append(valid_acc)\n",
    "\n",
    "    # 打印训练过程中的指标\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.4f}\")\n",
    "\n",
    "\n",
    "# 绘制训练和验证指标的图表\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(train_losses, label='Train Loss')\n",
    "ax.plot(train_accs, label='Train Accuracy')\n",
    "ax.plot(valid_losses, label='Validation Loss')\n",
    "ax.plot(valid_accs, label='Validation Accuracy')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_title('Training and Validation Metrics')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
